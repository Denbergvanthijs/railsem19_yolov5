{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the RailSem19 dataset\n",
    "\n",
    "\n",
    "The RailSem19 dataset can be obtained via [WildDash](https://wilddash.cc/railsem19).\n",
    "\n",
    "> O. Zendel, M. Murschitz, M. Zeilinger, D. Steininger, S. Abbasi and C. Beleznai, RailSem19: A Dataset for Semantic Rail Scene Understanding, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2019, pp. 1221-1229, doi: 10.1109/CVPRW.2019.00161."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_json(fp):\n",
    "    with open(fp) as f:\n",
    "        f_data = json.load(f)\n",
    "    return f_data\n",
    "\n",
    "data = read_json(\"./rs19_val/rs19-config.json\")\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available classes in the semantic segmentation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car',\n",
       " 'construction',\n",
       " 'fence',\n",
       " 'human',\n",
       " 'on-rails',\n",
       " 'pole',\n",
       " 'rail-embedded',\n",
       " 'rail-raised',\n",
       " 'rail-track',\n",
       " 'road',\n",
       " 'sidewalk',\n",
       " 'sky',\n",
       " 'terrain',\n",
       " 'trackbed',\n",
       " 'traffic-light',\n",
       " 'traffic-sign',\n",
       " 'tram-track',\n",
       " 'truck',\n",
       " 'vegetation']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted([entry[\"name\"] for entry in data[\"labels\"]])\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all JSON annotations of the object detection dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500 labels\n"
     ]
    }
   ],
   "source": [
    "fp_jsons = \"./rs19_val/jsons/rs19_val\"\n",
    "\n",
    "labels = [read_json(os.path.join(fp_jsons, file)) for file in os.listdir(fp_jsons)]\n",
    "print(f\"{len(labels)} labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classnames for the object detection dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 unique classes:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'buffer-stop',\n",
       " 'car',\n",
       " 'crossing',\n",
       " 'fence',\n",
       " 'guard-rail',\n",
       " 'person',\n",
       " 'person-group',\n",
       " 'platform',\n",
       " 'pole',\n",
       " 'rail',\n",
       " 'rail-occluder',\n",
       " 'switch-indicator',\n",
       " 'switch-left',\n",
       " 'switch-right',\n",
       " 'switch-static',\n",
       " 'switch-unknown',\n",
       " 'track-sign-front',\n",
       " 'track-signal-back',\n",
       " 'track-signal-front',\n",
       " 'train-car',\n",
       " 'truck'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_classes = set().union(*((obj[\"label\"] for obj in label[\"objects\"]) for label in labels))\n",
    "\n",
    "print(f\"{len(unique_classes)} unique classes:\")\n",
    "unique_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of images with at least one instance of the classes we're interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_person=167, n_person_group=48'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_person = sum((\"person\" in (obj[\"label\"] for obj in label[\"objects\"]) for label in labels))\n",
    "n_person_group = sum((\"person-group\" in (obj[\"label\"] for obj in label[\"objects\"]) for label in labels))\n",
    "\n",
    "f\"{n_person=}, {n_person_group=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of instances of the classes we're interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total_person=234, total_person_group=62'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_person = sum(sum(obj[\"label\"] == \"person\" for obj in label[\"objects\"]) for label in labels)\n",
    "total_person_group = sum(sum(obj[\"label\"] == \"person-group\" for obj in label[\"objects\"]) for label in labels)\n",
    "\n",
    "f\"{total_person=}, {total_person_group=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of unique images where at least one instance of one relevant class is present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_img_person = {label[\"frame\"] for label in labels if \"person\" in (l[\"label\"] for l in label[\"objects\"])}\n",
    "unique_img_person_group = {label[\"frame\"] for label in labels if \"person-group\" in (l[\"label\"] for l in label[\"objects\"])}\n",
    "\n",
    "len(unique_img_person | unique_img_person_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of unique images with at least one instance of the label `person` but without any instance of the label `person-group`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(unique_img_person) - set(unique_img_person_group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of unique images with at least one instance of the label `person-group` but without any instance of the label `person`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(unique_img_person_group) - set(unique_img_person))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
